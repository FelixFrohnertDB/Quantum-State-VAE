{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_size_dim    = 4\n",
    "golden_ratio    = (1+np.sqrt(5))/2\n",
    "fig_size        = (fig_size_dim, fig_size_dim/golden_ratio)\n",
    "\n",
    "def plot_style():\n",
    "    font_size       = 12\n",
    "    dpi             = 200\n",
    "\n",
    "    params = {'figure.figsize': fig_size,\n",
    "              'figure.dpi': dpi,\n",
    "              'savefig.dpi': dpi,\n",
    "              'font.size': font_size,\n",
    "              'font.family': \"sans-serif\",\n",
    "              'font.sans-serif': [\"Helvetica\"],\n",
    "              'figure.titlesize': font_size,\n",
    "              'legend.fontsize': font_size,\n",
    "              'axes.labelsize': font_size,\n",
    "              'axes.titlesize': font_size,\n",
    "              'xtick.labelsize': font_size,\n",
    "              'ytick.labelsize': font_size,\n",
    "              'text.usetex': True,\n",
    "             }\n",
    "\n",
    "    plt.rcParams.update(params)\n",
    "plot_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(tf.keras.layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a p-vector.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "class VAE(tf.keras.Model):\n",
    "    def __init__(self, encoder, decoder, beta_factor, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.beta = beta_factor\n",
    "        self.beta_scale = 1\n",
    "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\")\n",
    "        self.val_loss_tracker = tf.keras.metrics.Mean(\n",
    "            name=\"val_loss\")\n",
    "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            self.val_loss_tracker\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(tf.keras.losses.mean_squared_error(data, reconstruction), axis=-1))\n",
    "\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "\n",
    "            total_loss = reconstruction_loss + self.beta_scale * self.beta * kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result()\n",
    "        }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        _, _, z_test = self.encoder(data[0])\n",
    "        test_reconstruction = self.decoder(z_test)\n",
    "        val_loss = tf.reduce_mean(\n",
    "            tf.reduce_sum(tf.keras.losses.mean_squared_error(data[0], test_reconstruction), axis=-1))\n",
    "        self.val_loss_tracker.update_state(val_loss)\n",
    "        return {\"val_loss\": self.val_loss_tracker.result()}\n",
    "\n",
    "\n",
    "def vae_mlp_4x4(latent_dim, act_func, f_act):\n",
    "    encoder_inputs = tf.keras.Input(shape=16)\n",
    "    x = encoder_inputs\n",
    "    x = tf.keras.layers.Dense(16, activation=act_func)(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(8, activation=act_func)(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(4, activation=act_func)(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    z_mean = tf.keras.layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "    z_log_var = tf.keras.layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "    encoder = tf.keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "\n",
    "    latent_inputs = tf.keras.Input(shape=(latent_dim,))\n",
    "    x = latent_inputs\n",
    "    x = tf.keras.layers.Dense(4, activation=act_func)(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(8, activation=act_func)(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(16, activation=act_func)(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    decoder_outputs = tf.keras.layers.Dense(16, activation=f_act)(x)\n",
    "    decoder = tf.keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "\n",
    "    return encoder, decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h/J vs z phase transition \n",
    "\n",
    "h/z vs z mit mps/ed with different bond dimensions\n",
    "\n",
    "t vs z h0 to ht\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1d TFI model \n",
    "critical point \n",
    "quench in phase transition, \n",
    "high field low field \n",
    "\n",
    "two (k?) body correlators\n",
    "\n",
    "quimb for data generation \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(arr, time, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "beta = 0.00\n",
    "learning_rate = 0.005\n",
    "lat_dim = 8\n",
    "hidden_act = \"leaky_relu\"\n",
    "final_act = \"tanh\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load trained VAE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 12:26:08.123169: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-28 12:26:08.123198: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-28 12:26:08.123222: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (felix-Latitude-5521): /proc/driver/nvidia/version does not exist\n",
      "2023-03-28 12:26:08.123507: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step - loss: 5.1873 - reconstruction_loss: 4.8869 - kl_loss: 0.0490\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.7367 - reconstruction_loss: 3.5968 - kl_loss: 0.0338\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3417 - reconstruction_loss: 3.2380 - kl_loss: 0.0522\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.1572 - reconstruction_loss: 3.0797 - kl_loss: 0.0659\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.0981 - reconstruction_loss: 3.0097 - kl_loss: 0.0668\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.0521 - reconstruction_loss: 2.9903 - kl_loss: 0.0561\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.0166 - reconstruction_loss: 2.9674 - kl_loss: 0.0483\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3.0233 - reconstruction_loss: 2.9809 - kl_loss: 0.0437\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.0130 - reconstruction_loss: 2.9694 - kl_loss: 0.0356\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3.0252 - reconstruction_loss: 2.9737 - kl_loss: 0.0280\n",
      "8/8 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "encoder, decoder = vae_mlp_4x4(lat_dim, hidden_act, final_act)\n",
    "\n",
    "vae_noisy = VAE(encoder, decoder, beta)\n",
    "vae_noisy.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))\n",
    "vae_noisy.fit(X_test, epochs=10, batch_size=64, verbose=1) \n",
    "\n",
    "z_mean, z_log_var, z = vae_noisy.encoder.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
